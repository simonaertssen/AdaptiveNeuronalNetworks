\input{Setup.tex}
\begin{document}

\mainmatter

MFRs \today \\
Msc Thesis - Dynamics of adaptive neuronal networks. \\
Simon Aertssen (s181603), \today \\ 

\section{Writing out the whole system}
The network dynamics are described as follows:
\begin{align}
\frac{d \theta_i}{d t} &= (1 - \cos\theta_i) + (1 + \cos\theta_i)\cdot\left(\eta_i + I_i \right) \qquad \theta_i \in \T^N \nonumber \\
I_{i} &= \frac{\kappa}{\langle k\rangle} \sum_{j=1}^{N} A_{i j} P_{n}\left(\theta_{j}\right) \label{eq:FullThetaNeuronNetwork} \\
P_{n}\left(\theta_{j}\right) &= a_n (1 - \cos\theta_j) \nonumber
\end{align}

We observe synchronisation through the order parameter
\begin{align}
Z(t) = \frac{1}{N} \sum_{j=1}^N e^{\ic\theta_j}  \qquad Z(t) \in \C \label{eq:orderparameter}
\end{align}

For a fixed degree network it has been proven that the order parameter follows:
\begin{align}
\dot{Z}(t)= -\ic \frac{(Z-1)^2}{2}+\frac{(Z+1)^2}{2} \cdot \left(-\Delta+ \ic\eta_{0}
+ \ic \kappa \cdot \left(1+\frac{Z^{2} + \overline{Z}^{2} }{6} - \frac{4}{3} \Re(Z)\right)\right) \label{eq:MeanField}
\end{align}
    
For an arbitrary network the order parameter follows a trajectory per degree. When we assemble the whole expression for the Ott-Antonsen manifold as found in \cite{OttAntonsen2017} with $H_2(\k,t)$ as in \cite{Martens2020}, we obtain the following:
\begin{align}
\frac{\partial z(\k, t)}{\partial t} &= -\ic \frac{(z(\k, t)-1)^{2}}{2} + \frac{(z(\k, t)+1)^{2}}{2} \cdot I(\k) \qquad z(\k,t) \in \C^{M_\k} \nonumber \\
%I(\k) &= -\Delta(\k) + \ic \eta_{0}(\k) + i d_{n} \kappa \cdot H_n(\k,t) \label{eq:OttAntonsenSystemFull} \\
%H_n(\k,t) &= \frac{a_n}{\kmean} \sum_{\kacc} P\left(\kacc\right) a\left(\kacc \rightarrow \k\right) \cdot \left[A_{0}+\sum_{p=1}^{n} A_{p}\left(z\left(\kacc, t\right)^{p} + \overline{z}\left(\kacc, t\right)^{p}\right)\right] 
I(\k) &= -\Delta(\k) + \ic \eta_{0}(\k) + i \kappa \cdot H_2(\k,t) \label{eq:OttAntonsenSystemFull} \\
H_2(\k,t) &= \frac{1}{\kmean} \sum_{\kacc} P\left(\kacc\right) a\left(\kacc \rightarrow \k\right) \cdot \left( 1 + \frac{z(\kacc, t)^2 + \overline{z}(\kacc, t)^2}{6} - \frac{4}{3} \Re(z(\kacc, t)) \right) \nonumber
\end{align}

$\k$ represents a two-dimensional vector of the in- an out degree as $\k = ( \kin, \kout)$ and has unique entries as it forms the support of the vector of degrees of \eqref{eq:FullThetaNeuronNetwork} as $\degree(\theta_i)$. So $z(\k,t)$ is really a vector in the complex plane that represents the mean-field dynamics on any node with degree $\k$, so we could also index as $z(t)_{\k}$. $\kacc$ represents $\k$ when $\k$ is already in use.\\

We can then find the mean field dynamics through
\begin{align}
\overline{Z}(t) &= \frac{1}{N} \sum_{\k} P(\k) z(\k, t) \qquad \overline{Z}(t) \in \C \label{eq:OttAntonsenMeanField}
\end{align}

It is important to notice that in \eqref{eq:OttAntonsenSystemFull} and \eqref{eq:OttAntonsenMeanField} we actually compute an inner vector product, which is non-commutative for complex numbers:
\begin{align}
a \cdot b = \overline{b \cdot a} \qquad a, b \in \C^r
\end{align}
This is the result of the \textsl{Conjugate} or \textsl{Hermitian} symmetry of the inner product. This is especially important in the \matlab implementation.


\section{Initial conditions}
As the systems in \cref{eq:FullThetaNeuronNetwork,eq:orderparameter,eq:MeanField,eq:OttAntonsenSystemFull,eq:OttAntonsenMeanField} describe the same dynamics for fully connected networks, it is important to be able to transform initial conditions between systems. When transforming from $\theta_i(t) \rightarrow z(\k,t) \rightarrow Z(t)$ we go from $\T^N \rightarrow \C^{M_\k}$ to $\C^{M_\k} \rightarrow \C$. If we have the same initial conditions, then all systems will predict the same behaviour. We will only map everything to $\C$.\\
The following maps can be used to transform the initial conditions, but as they do not give any qualitative information on the dynamics or distributions of the variables, they are not valid for transforming between dynamics. We discard $t=0$ for clarity. \\
Mapping operations onto the order parameter in the complex plane is straightforward:
\begin{align*}
\theta_i \xrightarrow{\hspace*{8mm}} Z &= \frac{1}{N} \sum_{j=1}^N e^{\ic\theta_j} \\
z(\k) \longrightarrow Z &= \frac{1}{N} \sum_{\k} P(\k) z(\k, t)
\end{align*}

Taking the inverse maps, we can make use of the fact that the average of a set of identical values is the value itself. For $z(\k)$ we have a weighed average which we need to undo, making sure that the whole sums up to $N$.
\begin{align*}
Z \xrightarrow{\hspace*{9mm}} \theta_{i} &= -\ic \cdot \log \left( Z \right) \\
Z \longrightarrow z(\k) &= \overline{\frac{Z \cdot n(\k)}{P(\k)}}
\end{align*}

Then, transferring between $\theta_i$ and $z(\k)$, we need to filter $\theta_i$ per degree:
\begin{align*}
z(\k) \longrightarrow \theta_i &= -\ic \cdot \log \left( \frac{z(\k)\cdot P(\k)}{n(\k)} \right) \qquad \text{ if } \degree(\theta_i) = \k \\
\theta_i \longrightarrow z(\k) &= \sum_{\k} e^{\ic \vartheta_{\k}} \qquad \qquad \vartheta_{\k} = \sum_{i = 1}^{n(\k)} \theta_i \in 
\left\{ \theta_i \vert \degree(\theta_i) = \k, \forall i \leq N \right\}
\end{align*}
%Or also $\sum_i^N A_{ij} = k^{\rm in} \cup \sum_j^N A_{ij} = \kout$. 

We can see how $\lim_{N \rightarrow +\infty} n(\k) = P(\k)$, which makes these maps exact for any network size. 
    
\newpage
\section{Phase space}
\subsection{Fixed degree networks}
In the phase space, we can clearly distinguish three macroscopic states for the mean field:
\begin{figure}[H]
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth, trim={2cm 1cm 2cm 1.5cm },clip]{../Figures/MFRPSR.png}
  \caption{PSR state}\label{fig:MFRPSR}
\endminipage\hfill
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth, trim={2cm 1cm 2cm 1.5cm },clip]{../Figures/MFRPSS.png}
  \caption{PSS state}\label{fig:MFRPSS}
\endminipage\hfill
\minipage{0.32\textwidth}%
  \includegraphics[width=\linewidth, trim={2cm 1cm 2cm 1.5cm },clip]{../Figures/MFRCPW.png}
  \caption{CPW state}\label{fig:MFRCPW}
\endminipage
\end{figure}
For different networks this can look a little different.

\subsection{Random networks}
\begin{figure}[H]
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth, trim={2cm 1cm 2cm 1.5cm },clip]{../Figures/MFOARPSR_random.png}
  \caption{PSR state}\label{fig:MFRPSR}
\endminipage\hfill
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth, trim={2cm 1cm 2cm 1.5cm },clip]{../Figures/MFOARPSS_random.png}
  \caption{PSS state}\label{fig:MFRPSS}
\endminipage\hfill
\minipage{0.32\textwidth}%
  \includegraphics[width=\linewidth, trim={2cm 1cm 2cm 1.5cm },clip]{../Figures/MFOARCPW_random.png}
  \caption{CPW state}\label{fig:MFRCPW}
\endminipage
\end{figure}

\subsection{Scale Free networks}
\begin{figure}[H]
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth, trim={2cm 1cm 2cm 1.5cm },clip]{../Figures/MFOARPSR_scalefree.png}
  \caption{PSR state}\label{fig:MFRPSR}
\endminipage\hfill
\minipage{0.32\textwidth}
  \includegraphics[width=\linewidth, trim={2cm 1cm 2cm 1.5cm },clip]{../Figures/MFOARPSS_scalefree.png}
  \caption{PSS state}\label{fig:MFRPSS}
\endminipage\hfill
\minipage{0.32\textwidth}%
  \includegraphics[width=\linewidth, trim={2cm 1cm 2cm 1.5cm },clip]{../Figures/MFOARCPW_scalefree.png}
  \caption{CPW state}\label{fig:MFRCPW}
\endminipage
\end{figure}


\section{Differences between theory and practice}
\begin{figure}[H]
  \includegraphics[width=\linewidth]{../Figures/InspectMeanFieldFullyConnected.pdf}
  \caption{Mean field descriptions of fully connected networks.}\label{fig:InspectMeanFieldFullyConnected}
\end{figure}

\begin{figure}[H]
  \includegraphics[width=\linewidth]{../Figures/InspectMeanFieldFixedDegree.pdf}
  \caption{Mean field descriptions of fixed degree networks.}\label{fig:InspectMeanFieldFixedDegree}
\end{figure}

\begin{figure}[H]
  \includegraphics[width=\linewidth]{../Figures/InspectMeanFieldRandom.pdf}
  \caption{Mean field descriptions of random networks.}\label{fig:InspectMeanFieldRandom}
\end{figure}

\begin{figure}[H]
  \includegraphics[width=\linewidth]{../Figures/InspectMeanFieldScaleFree.pdf}
  \caption{Mean field descriptions of scale-free networks.}\label{fig:InspectMeanFieldScaleFree}
\end{figure}

\begin{figure}[H]
  \includegraphics[width=\linewidth]{../Figures/testScaleFree.png}
  \caption{The scale-free networks seem to converge to different limit cycles.}\label{fig:testScaleFree}
\end{figure}

\begin{figure}[H]
  \includegraphics[width=\linewidth]{../Figures/InspectMeanFieldLogNorm.pdf}
  \caption{Mean field descriptions of log-normal networks.}\label{fig:InspectMeanFieldLogNorm}
\end{figure}



\section{Fixpoint iteration}
In \cite{OttAntonsen2017} a fixpoint iteration is suggested to find attractive fixpoints of the system \eqref{eq:OttAntonsenSystemFull}. If we set $\frac{\partial z(\k, t)}{\partial t} = 0$ we can solve the following system:
\begin{align}
\ic \frac{(z(\k, t)-1)^{2}}{2} &= \frac{(z(\k, t)+1)^{2}}{2} \cdot I(\k) \nonumber \\
\ic \left(\frac{z(\k, t)-1}{z(\k, t)+1}\right)^2 &= I(\k) \nonumber \\
\frac{z(\k, t)-1}{z(\k, t)+1} &\equiv b(\k,t) \nonumber \\
z(\k, t) - 1 &= b(\k,t) z(\k, t) + b(\k,t)  \nonumber \\
z(\k, t) \cdot (1 - b(\k,t)) &= b(\k,t)  + 1\nonumber
\end{align}

We can then obtain the stable equilibria from:
\begin{align}
\ic b(\k,t)^2 = I(\k) \hspace{10mm} z(\k, t)_{\pm} = \frac{1 \pm b(\k,t)}{1 \mp b(\k,t)} \label{eq:fixedpointiterations} 
\end{align}
where the signs are chosen so that $\vert z(\k, t) \vert \leq 1$. This works.


\section{A Newton-Raphson iteration for all fixpoints}
\subsection{Theory behind the method}
The fixpoint iteration only gives us the stable equilibria of the system \eqref{eq:OttAntonsenSystemFull}. We can obtain all equilibria and the Jacobian from a Newton-Raphson iteration. We define the equilibria $\boldsymbol{x^\ast} \in \R^n$ of a multivariate function $\boldsymbol{f}(\boldsymbol{x}) : \R^n \rightarrow \R^n$ with $\boldsymbol{f}(\boldsymbol{x}) = \boldsymbol{0}$. Expanding $\boldsymbol{f}$ as a Taylor series, we obtain:
\begin{align}
f_i(\boldsymbol{x} + \delta \boldsymbol{x}) =f_{i}(\boldsymbol{x}) + \sum_{j=1}^{n} \frac{\partial f_{i}(\boldsymbol{x})}{\partial x_{j}} \delta x_{j}+O\left(\delta \boldsymbol{x}^{2}\right) \approx f_{i}(\boldsymbol{x})+\sum_{j=1}^{n} \frac{\partial f_{i}(\boldsymbol{x})}{\partial x_{j}} \delta x_{j}, \qquad (i=1, \cdots, n)
\end{align}

We can also write this in vector notation, by setting $\boldsymbol{J}(\boldsymbol{x}) = \nabla \boldsymbol{f}(\boldsymbol{x}) = \frac{d}{d\boldsymbol{x}} \boldsymbol{f}(\boldsymbol{x}) \in \R^{n \times n}$ 
\begin{align}
\boldsymbol{f}(\boldsymbol{x}+\delta \boldsymbol{x}) &\approx\left[\begin{array}{c}f_{1}(\boldsymbol{x}) \\ \vdots \\ f_{N}(\boldsymbol{x})\end{array}\right] 
+ \left[\begin{array}{ccc}\frac{\partial f_{1}}{\partial x_{1}} & \cdots & \frac{\partial f_{1}}{\partial x_{N}} \\ \vdots & \ddots & \vdots \\ \frac{\partial f_{N}}{\partial x_{1}} & \cdots & \frac{\partial f_{N}}{\partial x_{N}}\end{array}\right]
\left[\begin{array}{c}\delta x_{1} \\ \vdots \\ \delta x_{N}\end{array}\right] 
=\boldsymbol{f}(\boldsymbol{x})+\boldsymbol{J}(\boldsymbol{x}) \delta \boldsymbol{x} 
\end{align}

By assuming $\boldsymbol{f}(\boldsymbol{x}+\delta \boldsymbol{x}) = 0$ we can find that $\delta \boldsymbol{x} = -\boldsymbol{J}^{-1}( \boldsymbol{x}) \boldsymbol{f}(\boldsymbol{x})$ so that $\boldsymbol{x} + \delta \boldsymbol{x} =  \boldsymbol{x} - \boldsymbol{J}^{-1} (\boldsymbol{x}) \boldsymbol{f}(\boldsymbol{x})$. This expression converges to $\boldsymbol{x^\ast}$. When the equations are nonlinear, the equations converge to the real root as $\boldsymbol{x}_k =  \boldsymbol{x}_k - \boldsymbol{J}^{-1} ( \boldsymbol{x}_k)\boldsymbol{f}(\boldsymbol{x}_k)$. \\

For \eqref{eq:OttAntonsenSystemFull}, we can compute the Jacobian for the diagonal and off-diagonal elements separately. But as $z(\k,t)$ is a complex function, first we need to understand what the derivative of a complex function is. 


\subsection{Derivatives of complex functions}
For $z = x + \ic y \in \C$ and $x,y \in R$ the conjugate is defined as $\overline{z} = x - \ic y$. That means that we can write the real and imaginary parts as:
\begin{align*}
x = \frac{z + \overline{z}}{2} \text{  and   }   y = -\ic \frac{z - \overline{z}}{2}
\end{align*}
Using the chain rule, we can write the partial derivative with respect to $z$ in function of $x$ and $y$ as $x$ and $y$ are functionally independent and find the first Wirtinger operator:
\begin{align*}
\frac{\partial}{\partial z} =\frac{\partial x}{\partial z} \frac{\partial}{\partial x}+\frac{\partial \bar{y}}{\partial z} \frac{\partial}{\partial \overline{y}} 
\longrightarrow \frac{\partial x}{\partial z} = \frac{1}{2} \text{   and   } \frac{\partial y}{\partial z} =  - \frac{\ic}{2} 
\longrightarrow \frac{\partial}{\partial z} = \frac{1}{2}\left(\frac{\partial}{\partial x} - \ic \frac{\partial}{\partial y}\right)
\end{align*}
We note the following properties:
\begin{align*}
\frac{\partial}{\partial z} z = 1 \hspace{10mm} \frac{\partial}{\partial z}\overline{z} = \frac{1}{2}\left(1 - \ic^2 \right) = 0
\end{align*}
Interesting for is the result of the following: 
\begin{align*}
\overline{z}^2 &= (x - \ic y)^2 = x^2 - y^2 - \ic 2xy \\
\frac{\partial}{\partial z} \overline{z}^2 &=  \frac{1}{2}\cdot(2x -\ic 2y - \ic\cdot(-2y -\ic 2x)) = x -\ic y + \ic y -\ic x = 0
\end{align*}



\subsection{Derivatives of the complex mean field equations}
We can now compute derivatives of the complex functions $z(\k,t)$. We will set $z(\k, t) = z_{\k}$ and rewrite system \eqref{eq:OttAntonsenSystemFull} to help the reader:
\begin{align}
\frac{\partial z_{\k}}{\partial t} &= -\ic \frac{(z_{\k}-1)^{2}}{2} + \frac{(z_{\k}+1)^{2}}{2} \cdot I_{\k} \qquad z_{\k} \in \C^{M_\k} \nonumber \\
%I(\k) &= -\Delta(\k) + \ic \eta_{0}(\k) + i d_{n} \kappa \cdot H_n(\k,t) \label{eq:OttAntonsenSystemFull} \\
%H_n(\k,t) &= \frac{a_n}{\kmean} \sum_{\kacc} P\left(\kacc\right) a\left(\kacc \rightarrow \k\right) \cdot \left[A_{0}+\sum_{p=1}^{n} A_{p}\left(z\left(\kacc, t\right)^{p} + \overline{z}\left(\kacc, t\right)^{p}\right)\right] 
I_{\k} &= -\Delta_{\k} + \ic \eta_{0_{\k}} + i \kappa \cdot H_{2_{\k}} \label{eq:OttAntonsenSystemFull_k} \\
H_{2_{\k}} &= \frac{1}{\kmean} \sum_{\kacc} P_{\k} a_{\kacc \k} \cdot \left( 1 + \frac{z_{\kacc}^2 + \overline{z}_{\kacc}^2}{6} - \frac{4}{3} \Re(z_{\kacc}) \right) \nonumber
\end{align}

The diagonal elements are found as:
\begin{equation}
\begin{aligned}[b]
\frac{\partial}{\partial z_{\k}}\left(\frac{\partial z_{\k}}{\partial t} \right) &= - \ic(z_{\k} - 1) + (z_{\k} + 1) \cdot I_{\k} +  \frac{(z_{\k}+1)^{2}}{2} \cdot \frac{\partial I(z_{\k})}{\partial z_{\k}} \\
\frac{\partial I_{\k}}{\partial z_{\k}} &= \ic \kappa \cdot \frac{\partial H_{2_{\k}}}{\partial z_{\k}} \\
\frac{\partial H_{2_{\k}}}{\partial z_{\k}} &= \frac{1}{\kmean} P_{\k} a_{\k \k} \cdot \left(\frac{2 z_{\k}}{6} - \frac{4}{3} \cdot \frac{1}{2} \right) = \frac{1}{\kmean} P_{\k} a_{\k \k} \cdot\frac{z_{\k} - 2}{3}
\end{aligned}
\label{eq:OttAntonsenSystemJacobianDiagonal}
\end{equation}

The off-diagonal elements are found as
\begin{equation}
\begin{aligned}[b]
\frac{\partial}{\partial z_{\kacc}}\left(\frac{\partial z_{\k}}{\partial t} \right) &= \frac{(z_{\k} + 1)^{2}}{2} \cdot \frac{\partial I_{\k}}{\partial z_{\kacc}} \\
\frac{\partial I_{\k}}{\partial z_{\kacc}} &= \ic \kappa \cdot \frac{\partial H_{2_{\k}}}{\partial z_{\kacc}} \\
\frac{\partial H_{2_{\k}}}{\partial z_{\kacc}} &= \frac{1}{\kmean} P_{\kacc} a_{\kacc \k} \cdot \frac{z_{\kacc} - 2}{3}
\end{aligned}
\label{eq:OttAntonsenSystemJacobianOffDiagonal}
\end{equation}


\subsection{First results}
I cannot seem to converge close enough.
\begin{figure}[H]
\centering
\includegraphics[width = 0.75\textwidth]{../Figures/ProblemsWithNewtonRaphson.png}
\end{figure}


\subsection{Mapping onto $\R^2$}
$\bar{z}_{\k}$ and $\Re(z_{\k})$ are non-holomorphic. Try again by separating the real and imaginary part: $z(\k,t) = x(\k,t) + \ic y(\k,t)$.
\begin{align*}
\begin{aligned} \dot{x_{\k}} 
&=f_{n}\left(x_{\k}, y_{\k} ; \eta_{0}, \Delta, k\right) \\ 
&=(x_{\k}-1) y_{\k}-\frac{(x_{\k}+1)^{2}-y_{\k}^{2}}{2} \Delta-(x_{\k}+1) y_{\k} \cdot \left[\eta_{0}+ \kappa \cdot H(z, n)\right] \\ \dot{y_{\k}} &=g_{n}\left(x_{\k}, y_{\k} ; \eta_{0}, \Delta, k\right) \\ 
&=-\frac{(x_{\k}-1)^{2}-y_{\k}^{2}}{2}-(x_{\k}+1) y_{\k} \cdot \Delta+\frac{(x_{\k}+1)^{2}-y_{\k}^{2}}{2} \cdot \left[\eta_{0} + \kappa \cdot H_2(\k, t)\right] \end{aligned}
\end{align*}

The Jacobian can the be found from taking the derivatives?
\begin{align*}
\frac{\partial f_{n}}{\partial x_{\k}} &= y_{\k}-(x_{\k}+1) \cdot \Delta-y_{\k} \cdot \left[\eta_{0} + \kappa \cdot H_2(\k, t) \right] - (x_{\k}+1) \cdot y_{\k} \cdot \left(\kappa \cdot \frac{\partial H}{\partial x_{\k}}\right)\\
\frac{\partial f_{n}}{\partial y_{\k}} &= (x_{\k}-1)-y_{\k} \cdot \Delta-(x_{\k}+1) \cdot \left[\eta_{0} + \kappa \cdot H_2(\k, t) \right] \\t
\frac{\partial g_{n}}{\partial x_{\k}} &= -(x_{\k} - 1) - y_{\k} \cdot \Delta + (x_{\k} + 1) \cdot \left[\eta_{0} + \kappa \cdot H_2(\k, t) \right] + \left( \frac{(x_{\k} + 1)^2 - y_{\k}^2}{2} \right) \cdot \left(\kappa \cdot \frac{\partial H}{\partial x_{\k}}\right) \\
\frac{\partial g_{n}}{\partial y_{\k}} &= y_{\k} - (x_{\k} + 1)\cdot \Delta - y_{\k} \cdot \left[\eta_{0} + \kappa \cdot H_2(\k, t) \right] \\
\frac{\partial H_2(\k, t)}{\partial x_{\k}} &= \frac{1}{\langle k\rangle} P_{\k} a_{\k \k} \cdot(x_{\k}-2) \cdot \frac{2}{3} 
\end{align*}
What dimensions does the Jacobian have now?

\bibliographystyle{utphys}
\small{\bibliography{references}}

\label{LastPage}~

\end{document}
